---
title: "IS 607 Project 2"
author: "Chris Fenton"
date: "October 6, 2015"
output: html_document
---

For my second project in IS 607, I am tasked with taking 3 'wide' datasets,
tidying them according to the standards in this [Hadley Wickham paper](http://vita.had.co.nz/papers/tidy-data.pdf), and 
performing a bit of exploratory data analysis. The datasets were all proposed
by my peers in the IS 607 Fall 2015 cohort. The 3 datasets I chose were the 
2016 GOP presidential nomination polling data, all time MLB wins data, and 
2013-2015 Q1 United States import/export data.

As always, I'll load my libraries before beginning.

```{r message=FALSE}
library(tidyr)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
```

###1. 2016 GOP Presidential Nomination Polling Data

This dataset was proposed by Edwige Talla Badjio, and can be found in the
second table at this [link from Real Clear Politics](http://www.realclearpolitics.com/epolls/2016/president/us/2016_republican_presidential_nomination-3823.html#polls) (and coincentally, it looks like the website has undergone a face lift since I pulled the data).

Since the data comes from a tabular HTML format, it would have been possible
to use cURL to interact with the table directly, but in this case it was faster
to copy the data into excel and generate a .csv file that way.

I'll first load the .csv file, and use the na.strings argument to have R
"--" values as NA, since it represented no polling data for that candidate.

```{r}
gop <- read.csv('gop.csv', na.strings = "--")
```

The first step is to take a look at the data to get a feel for how it is
formatted and develop a strategy for tidying it.

```{r}
tbl_df(gop)
```

The data frame I am working with consists of a Poll variable, which describes
the organization that conducted the poll, a date variable, which describes the
time frame the polling data was collected, each candidate as a seperate
column, and a spread column indicating the top candidates lead over the 2nd 
place candidate.

Because the date ranges do not include years, and because most of the
candidates did not formally announce until this year, I will only look at
observations from 2015, and drop everything prior.

```{r}
gop <- gop[1:55,]
```

The most obvious violation of a tidy data format is that the candidates names,
which are variables, are used as columnn names. To fix this problem, I'll use
tidyr's gather() function to move them all into one column, and significantly 
reduce the 'width' of the data set. 

```{r}
gop <- gather(gop, candidate, points, Trump:Pataki)
tbl_df(gop)
```

I don't really care about the spread column, it's redundant, and I'll be 
able to easily calculate it later if I want, so I'll subset it out.

```{r eval=TRUE}
gop <- cbind(gop[1:2], gop[4:5])
```

I eventually want to look at this data as a function of time, so I need to get
the date data cleaned up. The intervals are all different, so I think the
best way to standardize this is to only look at the end date. I'll use a
regular expression to extract out the second date and replace the gop$Date
vector with the end date.

```{r}
gop$Date <- str_extract(gop$Date, "[[:digit:]]{1,2}/[[:digit:]]{1,2}$")
head(gop$Date)
```

The next issue is while I have the dates formatted the way I want, they are 
still character strings, thus won't compare to each other well. The solution
is to convert each to a POSIX time format using the strptime() function.

```{r}
gop$Date <- strptime(gop$Date,"%m/%d")
```

Last but not least is to coerce the polling points to numeric so they too can
be compared.

```{r}
gop$points <- as.numeric(gop$points)
```

I'll have a look at the df...
```{r warning=FALSE, message=FALSE}
tbl_df(gop)
```
...and the data looks tidy to me, so I'm ready to start exploring.

The webpage that this data pulls from has a line graph that plots all the 
candidates polling data as a function of time, color coded by candidate. 
I find it a bit difficult to read, so I'll see if I can do better.

My first step is to subset the top 5 candidates (sorry George Pataki).

```{r}
trump <- subset(gop, candidate == "Trump" & !is.na(points))
rubio <- subset(gop, candidate == "Rubio" & !is.na(points))
bush <- subset(gop, candidate == "Bush" & !is.na(points))
carson <- subset(gop, candidate == "Carson" & !is.na(points))
fiorina <- subset(gop, candidate == "Fiorina" & !is.na(points))
cruz <- subset(gop, candidate == "Cruz" & !is.na(points))
```

Next, I'll instantiate a ggplot object using Trump's data, and plot out
his numbers. What colo(u)r? We'll if you've ever seen Trump tower, you know
there's only one choice.

```{r}
gg <- ggplot(data=trump, aes(x=Date, y=points, colours='gold'))
gg + geom_point()
```

So this provides a pretty good feel for Trumps candidacy so far. His ascendancy
started around mid June, and dipped a bit towards the end of September.

Next, I'll compare how the estranged Florida candidates have performed:

```{r}
gg + geom_point(data=bush, colour ='red') + geom_point(data=rubio, colour='blue')
```

While Jeb! has been leading most of the way, it looks like he may have been passed
by his former understudy in recent weeks.

Finally, I'll look at all the top 6 candiates.

```{r}
horse_race <- gg +  geom_point(data=fiorina, colour ='black') + 
                    geom_point(data=rubio, colour='blue') + 
                    geom_point(data=trump, colour='gold') + 
                    geom_point(data=carson, colour='green') + 
                    geom_point(data=bush, colour='red')
horse_race
```

Despite Trumps downturn, he's still clearly in the lead. But the top candidates
seem to converging, indicating we're a long way from the convetion.

###2. All time MLB wins data

This data set was contributed by Nicholas Capofari and can be found on the 
[Baseball Reference site](http://www.baseball-reference.com/leagues/MLB/).
The data includes every MLB team from all time, there wins, and the games
played in that year.

If you click the link, the table can actually be converted into a .csv
format (but not downloaded, oddly). This makes the data a little bit easier
to get into a .csv file, but also means the header rows are repeated throughout
the file. To handle this, when I read in the data I will subset out those 
'header' records.

```{r}
mlb <- subset(read.csv('mlb.csv', stringsAsFactors = FALSE), Year != 'Year')
```

If I look at the structure of the data...

```{r}
str(mlb)
```

...I'll see that for whatever reason my stringsAsFactors option didn't work,
everything is still a factor. I'm guessing this is because of the junk records.

Anyway I need to handle this, and to do so I'll use lapply across the columns
of the data frame to coerce everything to numeric and that put it back in 
a data frame.

```{r}
mlb <- as.data.frame.list(lapply(mlb, function (x) as.numeric(x)))
tbl_df(mlb)
```

Similar to the last scenario, the major problem witht this dataset is that
there are variables as column names. Fortunately, tidyr makes this a very
easy problem to deal with.

```{r}
tidy_mlb <- gather(mlb, team, wins, ARI:WSN)
tbl_df(tidy_mlb)
```

Since the amount of games played each year varies, I'll add a win pct column
to make each observation directly comparable.

```{r}
tidy_mlb[,'win_pct'] <- tidy_mlb$wins / tidy_mlb$G
```

And with that I'm ready to look at the data.

Since baseball has been played seemingly forever, I'll mostly stick to looking 
at data since 1980. The first thing I'll look at is the best individual seasons.
```{r}
head(arrange(subset(tidy_mlb, Year >= 1980), desc(win_pct)))
```
Good show by the New York teams.

My favorite team is the Red Sox, so I'll single them out, looking at their
best and worst seasons.

```{r}
head(arrange(subset(tidy_mlb, Year >= 1980 & team == 'BOS'), desc(win_pct)))
head(arrange(subset(tidy_mlb, Year >= 1980 & team == 'BOS'), win_pct))
```
Now this is really interesting. Of the past 35 years, the Red Sox had their 
worst season, their second best season (where they won the World Series), 
and their second worst season. Maybe this explains why Boston sports fans
are so manic despite seemingly winning a title in a different sport every year.

Finally, I'll compare the Red Sox to their rival Yankees over that same time.

```{r}
mlb_80 <- subset(tidy_mlb, Year >= 1980)
boston <- subset(mlb_80, team == 'BOS')
nyy <- subset(mlb_80, team == 'NYY')
table(boston$wins > nyy$wins)
```

So despite the Sox recent success, the Yankees still get the better 
more often than not. 

###3. 2013-2015 Q1 United States Import/Export Data

The last dataset I chose was US trade data, contributed by Jason Joseph. Jason
was kind enough to provide a .csv file, so I'll load that in directly.

```{r}
trade_data <- read.csv("International Trade in Goods and Services.csv", 
                          stringsAsFactors = FALSE)
tbl_df(trade_data)
```

In spite of the fact that this is the smallest data set I am working with on this
project, it is also probably the most challenging to tidy. There are blank rows,
two header rows, and double row records.

The easiest issue to deal with are the blank rows, so I'll delete them out first
by subsetting out any row not blank in the X2013 column.

```{r}
trade_data <- subset(trade_data, X2013 != "")
tbl_df(trade_data)
```

Now that the empty space has been eliminated, I'll turn my attention to fixing
the fact that the observations span two columns. I can do this by filling in
the same month as the one above it.

```{r}
trade_data$Period[c(3,5,7,9)] <- c("January", "February","March","April")
tbl_df(trade_data)
```

These column names aren't very descriptive, but I can tell what they should be
using context clues, so I will fix those now. This also allows me to fix the
issue that there are two header rows. It creates another aspect of "untidyness"
by combining two variables into one column, but I'm not really chaning the data,
I'm just relabelling at this point.

```{r}
colnames(trade_data)[2] <- "goods_services"
colnames(trade_data)[3:8] <- c("2013 Exports","2013 Imports","2014 Exports",
                               "2014 Imports","2015 Exports", "2015 Imports")
trade_data <- trade_data[2:9,]
rownames(trade_data) <- 1:8
tbl_df(trade_data)
```


I want to do three things here. First, I want to narrow and lengthen the data
by eliminating the Year/Type columns and putting them in a variable field.
Since this also constitutes an example of more than one variable in a field,
I'll use separate to split them out using regex. Finally, the goods and services
are swung out as column names.

```{r}
tidy_trade <- trade_data %>%
                      gather("Year/Type", "Total", -Period, -goods_services)%>%  
                      separate("Year/Type", 
                                into = c("year", "import_export"), 
                                sep = "[[:space:]]")%>%
                      spread(goods_services, Total)
tbl_df(tidy_trade)
```

It looks good, but I kind of went back and forth as to whether Goods and Services
should be spread out as separate columns the way I did here. After all, it is just
a two level categorical value, just like import/export. Should the same be done 
with that variable?

I decided no because it would require combining import/exports with goods and
services. "Goods Imported" would be a column, for instance. While this would 
be a nice tabular display of the data, it seems like it would violate the variable
combination rule, so I abstained.

However, there is a bit more work to be done. Since the csv contained commas, the values
were imported as strings, therefore I am unable to compute at this point. The 
commas also prevent me from coercing directly to numeric (I thought R might be
able to figure this out, but I was wrong). In any event, it's a good opportunity to
practice Regex a bit more.

```{r}
tidy_trade$'Goods ' <- as.numeric(str_replace(tidy_trade$'Goods ', ",", ""))
tidy_trade$Services  <- as.numeric(str_replace(tidy_trade$Services , ",", ""))
```

Before I do the computations Jason inquired about, I'm going to split up imports
and exports into two separate data frames to make the subsetting a little easier.

```{r}
exports <- subset(tidy_trade, import_export == 'Exports')
imports <- subset(tidy_trade, import_export == 'Imports')
```

With that in hand, I can quickly and easily find the average accross months.

```{r}
#1. average goods exported for each month
mean(exports$Goods)

#2. avegage goods imported for each month
mean(imports$Goods)

#3. average services exported for each month
mean(exports$Services)

#4. average services imported for each month
mean(imports$Services)
```


